{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1979e24",
   "metadata": {},
   "source": [
    "\n",
    "# PytorchWildlife MegaDetector + Classifier Demo\n",
    "\n",
    "This notebook is a friendly wrapper around the original demo code for **image detection** and **species classification** using PytorchWildlife.\n",
    "\n",
    "It guides you through:\n",
    "1. Installing dependencies\n",
    "2. Choosing models & thresholds\n",
    "3. Running **single-image** detection + classification\n",
    "4. Running **batch** detection + classification\n",
    "5. Exporting annotated images, crops, JSON, and CSV\n",
    "6. Separating positive/negative results into folders\n",
    "\n",
    "> **GPU recommended** for speed (CUDA). Works on CPU too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ded27f",
   "metadata": {},
   "source": [
    "## 1) Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fa688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're in a fresh environment, uncomment the lines below. They install dependencies used in this demo.\n",
    "#\n",
    "# NOTE: On local machines with CUDA, ensure your PyTorch build matches your CUDA version:\n",
    "# See: https://pytorch.org/get-started/locally/\n",
    "#\n",
    "# !pip install --upgrade pip\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # Example for CUDA 12.1\n",
    "# !pip install supervision PytorchWildlife Pillow numpy tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6bb90",
   "metadata": {},
   "source": [
    "## 2) Imports & Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c15121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife import utils as pw_utils\n",
    "\n",
    "from PytorchWildlife.models import classification as pw_classification\n",
    "from PytorchWildlife.data import transforms as pw_trans\n",
    "from PytorchWildlife.data import datasets as pw_data \n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Running on CPU. This will work, but may be slower.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43473b4",
   "metadata": {},
   "source": [
    "## 3) Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9ebe4",
   "metadata": {},
   "source": [
    "- **Crop Detections:** Set `crop_detections = True` in the cell below to automatically save each detected object as a cropped image. The cropped outputs will be stored in the `CROP_OUT_DIR` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cbcbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crop_detections = False\n",
    "\n",
    "if crop_detections:\n",
    "    CROP_OUT_DIR = os.path.join(\".\", \"crop_output\")\n",
    "    os.makedirs(CROP_OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa6956",
   "metadata": {},
   "source": [
    "- **Detection Model Choice:** Set `USE_MDV5 = True` if you want to use MegaDetector V5, or select one of the valid MegaDetector V6 models by setting `MD_VERSION` as the desired version in the cell below. Supported options are:\n",
    "\n",
    "    - \"MDV6-yolov9-c\"\n",
    "    - \"MDV6-yolov9-e\"\n",
    "    - \"MDV6-yolov10-c\"\n",
    "    - \"MDV6-yolov10-e\"\n",
    "    - \"MDV6-rtdetr-c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_MDV5   = False  \n",
    "MD_VERSION = \"MDV6-yolov10-e\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b9b136",
   "metadata": {},
   "source": [
    "- **Classification Model Choice:** Set the `CLASSIFIER` variable to specify which classification model to use. The currently supported options are:\n",
    "\n",
    "    - \"AI4G_Amazon_v2\"\n",
    "    - \"DFNE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68103659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASSIFIER = \"AI4G_Amazon_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7497ffb",
   "metadata": {},
   "source": [
    "- **Thresholds:** Configure the confidence thresholds for detection and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493aac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASSIFIER_CONF_THRESH = 0.80\n",
    "DET_THRESH_FOR_FOLDER  = 0.20  \n",
    "CLF_THRESH_FOR_FOLDER  = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e13f51",
   "metadata": {},
   "source": [
    "- **Batch processing:** Set `BATCH_SIZE` to control how many images are processed in a single batch. Larger batch sizes can speed up processing but require more GPU/CPU memory, while smaller batch sizes reduce memory usage at the cost of slower throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74661f7",
   "metadata": {},
   "source": [
    "## 4) Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43502d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize detection model\n",
    "if not USE_MDV5:\n",
    "    detection_model = pw_detection.MegaDetectorV6(device=DEVICE, pretrained=True, version=MD_VERSION)\n",
    "else:\n",
    "    detection_model = pw_detection.MegaDetectorV5(device=DEVICE, pretrained=True, version=\"a\")\n",
    "\n",
    "# Initialize classification model\n",
    "if CLASSIFIER.lower().startswith(\"dfne\"):\n",
    "    classification_model = pw_classification.DFNE(device=DEVICE)\n",
    "else:\n",
    "    # default to AI4G Amazon Rainforest v2\n",
    "    classification_model = pw_classification.AI4GAmazonRainforest(device=DEVICE, version='v2')\n",
    "\n",
    "print(\"Models are ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41c126",
   "metadata": {},
   "source": [
    "## 5) Single-Image Detection + classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab956894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example paths. Change these to your data.\n",
    "SINGLE_IMAGE_PATH = os.path.join(\".\", \"demo_data\", \"imgs\", \"10050028_0.JPG\")\n",
    "SINGLE_OUT_DIR    = os.path.join(\".\", \"demo_output\")\n",
    "\n",
    "# Create output directory if needed\n",
    "os.makedirs(SINGLE_OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert os.path.exists(SINGLE_IMAGE_PATH), f\"Image not found: {SINGLE_IMAGE_PATH}\"\n",
    "\n",
    "# Run detection\n",
    "results = detection_model.single_image_detection(SINGLE_IMAGE_PATH)\n",
    "\n",
    "# Optionally run classifier only on detections labeled 'animal' (class id 0 in MD categories)\n",
    "input_img = np.array(Image.open(SINGLE_IMAGE_PATH).convert('RGB'))\n",
    "from typing import List\n",
    "clf_labels = []\n",
    "\n",
    "for i, (xyxy, det_id) in enumerate(zip(results[\"detections\"].xyxy, results[\"detections\"].class_id)):\n",
    "    if det_id == 0:  # animal\n",
    "        cropped_image = sv.crop_image(image=input_img, xyxy=xyxy)\n",
    "        results_clf = classification_model.single_image_classification(cropped_image)\n",
    "        label = (\n",
    "            f'{results_clf[\"prediction\"]} {results_clf[\"confidence\"]:.2f}'\n",
    "            if results_clf[\"confidence\"] > CLASSIFIER_CONF_THRESH\n",
    "            else f'Unknown {results_clf[\"confidence\"]:.2f}'\n",
    "        )\n",
    "        clf_labels.append(label)\n",
    "    else:\n",
    "        clf_labels.append(results[\"labels\"][i])\n",
    "\n",
    "results[\"labels\"] = clf_labels\n",
    "\n",
    "# Save annotated image & crops\n",
    "pw_utils.save_detection_images(results, SINGLE_OUT_DIR, overwrite=False)\n",
    "print(f\"Saved annotated image(s) to: {SINGLE_OUT_DIR}\")\n",
    "\n",
    "if crop_detections:\n",
    "    pw_utils.save_crop_images(results, CROP_OUT_DIR, overwrite=False)\n",
    "    print(f\"Saved crop(s) to: {CROP_OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58afc0",
   "metadata": {},
   "source": [
    "## 6) Batch Detection + Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example paths. Change these to your data.\n",
    "BATCH_INPUT_DIR   = os.path.join(os.getcwd(), \"demo_data\", \"classification_examples\")\n",
    "BATCH_DET_OUT_DIR = BATCH_INPUT_DIR.rstrip(os.sep) + \"_outputs\"\n",
    "\n",
    "# Create output directory if needed\n",
    "os.makedirs(BATCH_DET_OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert os.path.isdir(BATCH_INPUT_DIR), f\"Folder not found: {BATCH_INPUT_DIR}\"\n",
    "\n",
    "# Batch detection\n",
    "det_results = detection_model.batch_image_detection(BATCH_INPUT_DIR, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Batch classification (runs only for animal detections internally)\n",
    "clf_results = classification_model.batch_image_classification(det_results=det_results)\n",
    "\n",
    "# Merge detection + classification labels\n",
    "merged_results = det_results.copy()\n",
    "clf_conf_thres = CLASSIFIER_CONF_THRESH\n",
    "clf_counter = 0\n",
    "\n",
    "for det in merged_results:\n",
    "    clf_labels = []\n",
    "    for i, (xyxy, det_id) in enumerate(zip(det[\"detections\"].xyxy, det[\"detections\"].class_id)):\n",
    "        if det_id == 0:\n",
    "            pred = clf_results[clf_counter][\"prediction\"]\n",
    "            conf = clf_results[clf_counter][\"confidence\"]\n",
    "            label = f\"{pred if conf > clf_conf_thres else 'Unknown'} {conf:.2f}\"\n",
    "            clf_labels.append(label)\n",
    "            clf_counter += 1\n",
    "        else:\n",
    "            clf_labels.append(det[\"labels\"][i])\n",
    "    det[\"labels\"] = clf_labels\n",
    "\n",
    "# Save outputs\n",
    "pw_utils.save_detection_images(merged_results, BATCH_DET_OUT_DIR, BATCH_INPUT_DIR, overwrite=False)\n",
    "if crop_detections:\n",
    "    pw_utils.save_crop_images(merged_results, CROP_OUT_DIR, BATCH_INPUT_DIR, overwrite=False)\n",
    "\n",
    "json_out = os.path.join(BATCH_DET_OUT_DIR, \"batch_output_classification.json\")\n",
    "json_out_timelapse = os.path.join(BATCH_DET_OUT_DIR, \"batch_output_classification_timelapse.json\")\n",
    "csv_out  = os.path.join(BATCH_DET_OUT_DIR, \"batch_output_classification.csv\")\n",
    "\n",
    "pw_utils.save_detection_classification_json(\n",
    "    det_results=det_results,\n",
    "    clf_results=clf_results,\n",
    "    det_categories=detection_model.CLASS_NAMES,\n",
    "    clf_categories=classification_model.CLASS_NAMES,\n",
    "    output_path=json_out\n",
    ")\n",
    "\n",
    "pw_utils.save_detection_classification_timelapse_json(\n",
    "    det_results=det_results,\n",
    "    clf_results=clf_results,\n",
    "    det_categories=detection_model.CLASS_NAMES,\n",
    "    clf_categories=classification_model.CLASS_NAMES,\n",
    "    output_path=json_out_timelapse\n",
    ")\n",
    "\n",
    "pw_utils.save_detection_classification_csv(\n",
    "    det_results=det_results,\n",
    "    clf_results=clf_results,\n",
    "    det_categories=detection_model.CLASS_NAMES,\n",
    "    clf_categories=classification_model.CLASS_NAMES,\n",
    "    output_path=csv_out,\n",
    "    model_name=MD_VERSION if not USE_MDV5 else \"MDV5-a\"\n",
    ")\n",
    "\n",
    "print(\"Batch outputs saved:\")\n",
    "print(\" - Annotated images:\", BATCH_DET_OUT_DIR)\n",
    "if crop_detections:\n",
    "    print(\" - Crops:\", CROP_OUT_DIR)\n",
    "print(\" - JSON:\", json_out)\n",
    "print(\" - Timelapse JSON:\", json_out_timelapse)\n",
    "print(\" - CSV:\", csv_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483170fe",
   "metadata": {},
   "source": [
    "## 7) Positive/Negative Folder Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_SEP_OUT = os.path.join(\".\", \"folder_separation\")\n",
    "os.makedirs(FOLDER_SEP_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f775ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = os.path.join(BATCH_DET_OUT_DIR, \"batch_output_classification.json\")\n",
    "output_path = FOLDER_SEP_OUT\n",
    "det_threshold = DET_THRESH_FOR_FOLDER\n",
    "clf_threshold = CLF_THRESH_FOR_FOLDER\n",
    "overwrite = True\n",
    "draw_bboxes = True\n",
    "\n",
    "assert os.path.isfile(json_file), f\"JSON not found (run the batch cell first): {json_file}\"\n",
    "pw_utils.detection_classification_folder_separation(\n",
    "    json_file,\n",
    "    BATCH_INPUT_DIR,\n",
    "    output_path,\n",
    "    det_threshold,\n",
    "    clf_threshold,\n",
    "    overwrite,\n",
    "    draw_bboxes\n",
    ")\n",
    "print(f\"Separated images saved under: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PytorchWildlife_Demo.ipynb"
  },
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
