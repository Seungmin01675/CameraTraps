{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1979e24",
   "metadata": {},
   "source": [
    "\n",
    "# PytorchWildlife MegaDetector + Classifier Demo\n",
    "\n",
    "This notebook is a friendly wrapper around the original demo code for **image detection** and **species classification** using PytorchWildlife.\n",
    "\n",
    "It guides you through:\n",
    "1. Installing dependencies\n",
    "2. Choosing models & thresholds\n",
    "3. Running **single-image** detection + classification\n",
    "4. Running **batch** detection + classification\n",
    "5. Exporting annotated images, crops, JSON, and CSV\n",
    "6. Separating positive/negative results into folders\n",
    "\n",
    "> **GPU recommended** for speed (CUDA). Works on CPU too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ded27f",
   "metadata": {},
   "source": [
    "## 1) Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fa688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're in a fresh environment, uncomment the lines below. They install dependencies used in this demo.\n",
    "#\n",
    "# NOTE: On local machines with CUDA, ensure your PyTorch build matches your CUDA version:\n",
    "# See: https://pytorch.org/get-started/locally/\n",
    "#\n",
    "# !pip install --upgrade pip\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # Example for CUDA 12.1\n",
    "# !pip install supervision PytorchWildlife Pillow numpy tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6bb90",
   "metadata": {},
   "source": [
    "## 2) Imports & Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c15121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA version: 12.4\n",
      "GPU name: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife import utils as pw_utils\n",
    "\n",
    "from PytorchWildlife.models import classification as pw_classification\n",
    "from PytorchWildlife.data import transforms as pw_trans\n",
    "from PytorchWildlife.data import datasets as pw_data \n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Running on CPU. This will work, but may be slower.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43473b4",
   "metadata": {},
   "source": [
    "## 3) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c53a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "SINGLE_IMAGE_PATH: ./demo_data/imgs/10050028_0.JPG\n",
      "BATCH_INPUT_DIR  : /home/v-druizlopez/ssdprivate/CameraTraps/demo/demo_data/classification_examples\n",
      "MD_VERSION       : MDV6-yolov10-e (MDv5? False)\n",
      "CLASSIFIER       : AI4G_Amazon_v2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Paths ---\n",
    "# Provide example paths. Change these to your data.\n",
    "# A few sample folders expected by the original demo:\n",
    "SINGLE_IMAGE_PATH = os.path.join(\".\", \"demo_data\", \"imgs\", \"10050028_0.JPG\")\n",
    "BATCH_INPUT_DIR   = os.path.join(os.getcwd(), \"demo_data\", \"classification_examples\")\n",
    "\n",
    "# Output dirs (created if they don't exist)\n",
    "SINGLE_OUT_DIR    = os.path.join(\".\", \"demo_output\")\n",
    "BATCH_DET_OUT_DIR = os.path.join(\".\", \"batch_output\")\n",
    "CROP_OUT_DIR      = os.path.join(\".\", \"crop_output\")\n",
    "FOLDER_SEP_OUT    = os.path.join(\".\", \"folder_separation\")\n",
    "\n",
    "for p in [SINGLE_OUT_DIR, BATCH_DET_OUT_DIR, CROP_OUT_DIR, FOLDER_SEP_OUT]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# --- Detection model choice ---\n",
    "# Valid MegaDetector V6 versions:\n",
    "#   \"MDV6-yolov9-c\", \"MDV6-yolov9-e\", \"MDV6-yolov10-c\", \"MDV6-yolov10-e\", \"MDV6-rtdetr-c\"\n",
    "MD_VERSION = \"MDV6-yolov10-e\"   # change as needed\n",
    "USE_MDV5   = False              # set True to use MegaDetector V5 (version=\"a\")\n",
    "\n",
    "# --- Classification model choice ---\n",
    "# Options include DFNE(), AI4GAmazonRainforest(version='v2'), etc.\n",
    "CLASSIFIER = \"AI4G_Amazon_v2\"   # or \"DFNE\"\n",
    "\n",
    "# --- Thresholds ---\n",
    "CLASSIFIER_CONF_THRESH = 0.80\n",
    "DET_THRESH_FOR_FOLDER  = 0.20   # used in folder separation\n",
    "CLF_THRESH_FOR_FOLDER  = 0.20\n",
    "\n",
    "# --- Batch processing ---\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"SINGLE_IMAGE_PATH: {SINGLE_IMAGE_PATH}\")\n",
    "print(f\"BATCH_INPUT_DIR  : {BATCH_INPUT_DIR}\")\n",
    "print(f\"MD_VERSION       : {MD_VERSION} (MDv5? {USE_MDV5})\")\n",
    "print(f\"CLASSIFIER       : {CLASSIFIER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74661f7",
   "metadata": {},
   "source": [
    "## 4) Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43502d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.55 ðŸš€ Python-3.10.16 torch-2.5.1+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,589,858 parameters, 0 gradients, 169.8 GFLOPs\n",
      "Models are ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize detection model\n",
    "if not USE_MDV5:\n",
    "    detection_model = pw_detection.MegaDetectorV6(device=DEVICE, pretrained=True, version=MD_VERSION)\n",
    "else:\n",
    "    detection_model = pw_detection.MegaDetectorV5(device=DEVICE, pretrained=True, version=\"a\")\n",
    "\n",
    "# Initialize classification model\n",
    "if CLASSIFIER.lower().startswith(\"dfne\"):\n",
    "    classification_model = pw_classification.DFNE(device=DEVICE)\n",
    "else:\n",
    "    # default to AI4G Amazon Rainforest v2\n",
    "    classification_model = pw_classification.AI4GAmazonRainforest(device=DEVICE, version='v2')\n",
    "\n",
    "print(\"Models are ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41c126",
   "metadata": {},
   "source": [
    "## 5) Single-Image Detection + classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb1849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 992x1280 2 animals, 57.2ms\n",
      "Speed: 8.0ms preprocess, 57.2ms inference, 16.5ms postprocess per image at shape (1, 3, 992, 1280)\n",
      "Saved annotated image(s) to: ./demo_output\n",
      "Saved crop(s) to: ./crop_output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert os.path.exists(SINGLE_IMAGE_PATH), f\"Image not found: {SINGLE_IMAGE_PATH}\"\n",
    "\n",
    "# Run detection\n",
    "results = detection_model.single_image_detection(SINGLE_IMAGE_PATH)\n",
    "\n",
    "# Optionally run classifier only on detections labeled 'animal' (class id 0 in MD categories)\n",
    "input_img = np.array(Image.open(SINGLE_IMAGE_PATH).convert('RGB'))\n",
    "from typing import List\n",
    "clf_labels = []\n",
    "\n",
    "for i, (xyxy, det_id) in enumerate(zip(results[\"detections\"].xyxy, results[\"detections\"].class_id)):\n",
    "    if det_id == 0:  # animal\n",
    "        cropped_image = sv.crop_image(image=input_img, xyxy=xyxy)\n",
    "        results_clf = classification_model.single_image_classification(cropped_image)\n",
    "        label = (\n",
    "            f'{results_clf[\"prediction\"]} {results_clf[\"confidence\"]:.2f}'\n",
    "            if results_clf[\"confidence\"] > CLASSIFIER_CONF_THRESH\n",
    "            else f'Unknown {results_clf[\"confidence\"]:.2f}'\n",
    "        )\n",
    "        clf_labels.append(label)\n",
    "    else:\n",
    "        clf_labels.append(results[\"labels\"][i])\n",
    "\n",
    "results[\"labels\"] = clf_labels\n",
    "\n",
    "# Save annotated image & crops\n",
    "pw_utils.save_detection_images(results, SINGLE_OUT_DIR, overwrite=False)\n",
    "pw_utils.save_crop_images(results, CROP_OUT_DIR, overwrite=False)\n",
    "\n",
    "print(f\"Saved annotated image(s) to: {SINGLE_OUT_DIR}\")\n",
    "print(f\"Saved crop(s) to: {CROP_OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58afc0",
   "metadata": {},
   "source": [
    "## 6) Batch Detection + Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c28b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 1 animal, 61.6ms\n",
      "1: 1280x1280 1 animal, 61.6ms\n",
      "2: 1280x1280 1 animal, 61.6ms\n",
      "3: 1280x1280 1 animal, 61.6ms\n",
      "4: 1280x1280 2 animals, 61.6ms\n",
      "5: 1280x1280 1 animal, 61.6ms\n",
      "6: 1280x1280 1 animal, 61.6ms\n",
      "7: 1280x1280 1 animal, 61.6ms\n",
      "8: 1280x1280 1 animal, 61.6ms\n",
      "9: 1280x1280 2 animals, 61.6ms\n",
      "10: 1280x1280 1 animal, 61.6ms\n",
      "11: 1280x1280 4 animals, 61.6ms\n",
      "Speed: 13.7ms preprocess, 61.6ms inference, 1.9ms postprocess per image at shape (12, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.27s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch outputs saved:\n",
      " - Annotated images: ./batch_output\n",
      " - Crops: ./crop_output\n",
      " - JSON: ./batch_output_classification.json\n",
      " - Timelapse JSON: ./batch_output_classification_timelapse.json\n",
      " - CSV: ./batch_output_classification.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert os.path.isdir(BATCH_INPUT_DIR), f\"Folder not found: {BATCH_INPUT_DIR}\"\n",
    "\n",
    "# Batch detection\n",
    "det_results = detection_model.batch_image_detection(BATCH_INPUT_DIR, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Batch classification (runs only for animal detections internally)\n",
    "clf_results = classification_model.batch_image_classification(det_results=det_results)\n",
    "\n",
    "# Merge detection + classification labels\n",
    "merged_results = det_results.copy()\n",
    "clf_conf_thres = CLASSIFIER_CONF_THRESH\n",
    "clf_counter = 0\n",
    "\n",
    "for det in merged_results:\n",
    "    clf_labels = []\n",
    "    for i, (xyxy, det_id) in enumerate(zip(det[\"detections\"].xyxy, det[\"detections\"].class_id)):\n",
    "        if det_id == 0:\n",
    "            pred = clf_results[clf_counter][\"prediction\"]\n",
    "            conf = clf_results[clf_counter][\"confidence\"]\n",
    "            label = f\"{pred if conf > clf_conf_thres else 'Unknown'} {conf:.2f}\"\n",
    "            clf_labels.append(label)\n",
    "            clf_counter += 1\n",
    "        else:\n",
    "            clf_labels.append(det[\"labels\"][i])\n",
    "    det[\"labels\"] = clf_labels\n",
    "\n",
    "# Save outputs\n",
    "pw_utils.save_detection_images(merged_results, BATCH_DET_OUT_DIR, BATCH_INPUT_DIR, overwrite=False)\n",
    "pw_utils.save_crop_images(merged_results, CROP_OUT_DIR, BATCH_INPUT_DIR, overwrite=False)\n",
    "\n",
    "json_out = os.path.join(\".\", \"batch_output_classification.json\")\n",
    "json_out_timelapse = os.path.join(\".\", \"batch_output_classification_timelapse.json\")\n",
    "csv_out  = os.path.join(\".\", \"batch_output_classification.csv\")\n",
    "\n",
    "pw_utils.save_detection_classification_json(\n",
    "    det_results=det_results,\n",
    "    clf_results=clf_results,\n",
    "    det_categories=detection_model.CLASS_NAMES,\n",
    "    clf_categories=classification_model.CLASS_NAMES,\n",
    "    output_path=json_out\n",
    ")\n",
    "\n",
    "pw_utils.save_detection_classification_timelapse_json(\n",
    "    det_results=det_results,\n",
    "    clf_results=clf_results,\n",
    "    det_categories=detection_model.CLASS_NAMES,\n",
    "    clf_categories=classification_model.CLASS_NAMES,\n",
    "    output_path=json_out_timelapse\n",
    ")\n",
    "\n",
    "pw_utils.save_detection_classification_csv(\n",
    "    det_results=det_results,\n",
    "    clf_results=clf_results,\n",
    "    det_categories=detection_model.CLASS_NAMES,\n",
    "    clf_categories=classification_model.CLASS_NAMES,\n",
    "    output_path=csv_out,\n",
    "    model_name=MD_VERSION if not USE_MDV5 else \"MDV5-a\"\n",
    ")\n",
    "\n",
    "print(\"Batch outputs saved:\")\n",
    "print(\" - Annotated images:\", BATCH_DET_OUT_DIR)\n",
    "print(\" - Crops:\", CROP_OUT_DIR)\n",
    "print(\" - JSON:\", json_out)\n",
    "print(\" - Timelapse JSON:\", json_out_timelapse)\n",
    "print(\" - CSV:\", csv_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483170fe",
   "metadata": {},
   "source": [
    "## 7) Positive/Negative Folder Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f775ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated images saved under: ./folder_separation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_file = os.path.join(\".\", \"batch_output_classification.json\")\n",
    "output_path = FOLDER_SEP_OUT\n",
    "det_threshold = DET_THRESH_FOR_FOLDER\n",
    "clf_threshold = CLF_THRESH_FOR_FOLDER\n",
    "overwrite = True\n",
    "draw_bboxes = True\n",
    "\n",
    "assert os.path.isfile(json_file), f\"JSON not found (run the batch cell first): {json_file}\"\n",
    "pw_utils.detection_classification_folder_separation(\n",
    "    json_file,\n",
    "    BATCH_INPUT_DIR,\n",
    "    output_path,\n",
    "    det_threshold,\n",
    "    clf_threshold,\n",
    "    overwrite,\n",
    "    draw_bboxes\n",
    ")\n",
    "print(f\"Separated images saved under: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PytorchWildlife_Demo.ipynb"
  },
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
