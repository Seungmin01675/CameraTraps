{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4210d6e4",
   "metadata": {},
   "source": [
    "\n",
    "# 🐾 Wildlife Speed Tracking\n",
    "\n",
    "Welcome! This notebook helps you **detect, classify, and estimate 2D speeds** of animals in videos using **PyTorchWildlife**.  \n",
    "\n",
    "> **What you’ll get**: Annotated videos saved to an output folder, plus a `speed.csv` summarizing speeds per tracked object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe19d7",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Requirements\n",
    "\n",
    "- Python 3.9+ recommended\n",
    "- GPU optional (CUDA speeds things up, but CPU works too)\n",
    "- Videos placed in a folder (default: `./demo_data/speed_tracking_videos`)\n",
    "\n",
    "### 📦 Install dependencies\n",
    "\n",
    "> If you already have the packages, you can **skip** this cell. If needed, uncomment to install (recommended to run one-by-one if you hit errors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30510b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install --upgrade pip\n",
    "# %pip install supervision\n",
    "# %pip install ipywidgets tqdm pandas matplotlib\n",
    "# %pip install PytorchWildlife\n",
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a116ed",
   "metadata": {},
   "source": [
    "\n",
    "## 📥 Imports\n",
    "This cell imports everything we need and validates the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b1b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import supervision as sv\n",
    "\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife.models import classification as pw_classification\n",
    "from PytorchWildlife import utils as pw_utils\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b066ee",
   "metadata": {},
   "source": [
    "\n",
    "## 🎛️ Configure Inputs\n",
    "\n",
    "- **Height (optional):** Use the cell below to set `animal_height_m` in meters to convert speeds from **px/s → m/s** (conversion: `m/s = (px/s * animal_height_m) / image_width_px`). Leave it `None` to keep speeds in **px/s**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed0a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "animal_height_m = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14285a8",
   "metadata": {},
   "source": [
    "- **Video content:** Use the cell below to specify what your videos contain. This choice controls how tracks are selected:\n",
    "\n",
    "    - *One individual* → keep only the single longest track (best when a single animal is present).\n",
    "    - *Group of animals* → keep all tracks (best when multiple animals may appear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a2d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assume_single_individual = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87768843",
   "metadata": {},
   "source": [
    "\n",
    "- **Folders**: where videos live and where outputs should go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfe637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE_FOLDER_PATH = ./demo_data/speed_tracking_videos\n",
      "OUTPUT_FOLDER      = ./speed_tracking_output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SOURCE_FOLDER_PATH = os.path.join(\".\", \"demo_data\", \"speed_tracking_videos\")\n",
    "OUTPUT_FOLDER = os.path.join(\".\", \"speed_tracking_output\")\n",
    "\n",
    "Path(OUTPUT_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"SOURCE_FOLDER_PATH = {SOURCE_FOLDER_PATH}\")\n",
    "print(f\"OUTPUT_FOLDER      = {OUTPUT_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b07fa2",
   "metadata": {},
   "source": [
    "\n",
    "## 🖥️ Device\n",
    "Selects GPU (CUDA) if available, otherwise CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cad197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    try:\n",
    "        dev_name = torch.cuda.get_device_name(0)\n",
    "    except Exception:\n",
    "        dev_name = \"CUDA device\"\n",
    "    print(f\"Using GPU: {dev_name}\")\n",
    "else:\n",
    "    print(\"Using CPU (this may be slower).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc63596",
   "metadata": {},
   "source": [
    "\n",
    "## 🧠 Load Models\n",
    "- **Detector**: MegaDetector V6 (YOLOv9-c backbone)\n",
    "- **Classifier**: AI4G Amazon Rainforest (v2)\n",
    "\n",
    "> First run may download weights. If downloads fail, check internet/firewall settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e910260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.55 🚀 Python-3.10.16 torch-2.5.1+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv9c summary (fused): 384 layers, 25,321,561 parameters, 0 gradients, 102.3 GFLOPs\n",
      "✅ Models loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You can switch versions here if needed.\n",
    "DETECTION_VERSION = \"MDV6-yolov9-c\"\n",
    "CLASSIFICATION_VERSION = \"v2\"\n",
    "\n",
    "try:\n",
    "    detection_model = pw_detection.MegaDetectorV6(device=DEVICE, pretrained=True, version=DETECTION_VERSION)\n",
    "    classification_model = pw_classification.AI4GAmazonRainforest(device=DEVICE, version=CLASSIFICATION_VERSION)\n",
    "    print(\"✅ Models loaded\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"Failed to load models. Verify your PyTorchWildlife install and network access for weights.\"\n",
    "    ) from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde0c14",
   "metadata": {},
   "source": [
    "\n",
    "## 🖍️ Annotators\n",
    "Configure bounding boxes and labels for the output videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4964cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotators ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "box_annotator = sv.BoxAnnotator(thickness=4)\n",
    "lab_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK, text_thickness=4, text_scale=2)\n",
    "print(\"Annotators ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f5cf9",
   "metadata": {},
   "source": [
    "\n",
    "## 🔁 Detection & Classification Callback\n",
    "\n",
    "This function:\n",
    "1. Detects animals in the frame  \n",
    "2. Classifies each detection (cropped region)  \n",
    "3. Draws boxes & labels for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ce9a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Dict\n",
    "\n",
    "def callback(frame: np.ndarray, index: int) -> Tuple[np.ndarray, sv.Detections, List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        frame: Current video frame (H,W,3)\n",
    "        index: Frame index or identifier (passed to detector for metadata)\n",
    "    Returns:\n",
    "        annotated_frame: Frame with boxes+labels\n",
    "        detections: Supervision Detections object\n",
    "        clf_labels: List of (prediction, confidence) per detection in the same order\n",
    "    \"\"\"\n",
    "    results_det: Dict = detection_model.single_image_detection(frame, img_path=index)\n",
    "\n",
    "    clf_labels: List[Tuple[str, float]] = []\n",
    "    for xyxy in results_det[\"detections\"].xyxy:\n",
    "        cropped_image = sv.crop_image(image=frame, xyxy=xyxy)\n",
    "        results_clf = classification_model.single_image_classification(cropped_image)\n",
    "        clf_labels.append((results_clf[\"prediction\"], results_clf[\"confidence\"]))\n",
    "\n",
    "    annotated_frame = lab_annotator.annotate(\n",
    "        scene=box_annotator.annotate(scene=frame, detections=results_det[\"detections\"]),\n",
    "        detections=results_det[\"detections\"],\n",
    "        labels=results_det[\"labels\"]\n",
    "    )\n",
    "\n",
    "    return annotated_frame, results_det[\"detections\"], clf_labels\n",
    "\n",
    "print(\"Callback ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58919afd",
   "metadata": {},
   "source": [
    "\n",
    "## 📊 Prepare Speed Table\n",
    "We’ll create a DataFrame that stores **t1/x1/y1 → t2/x2/y2** and a computed speed column:\n",
    "- If a **species** is chosen, speeds convert to **m/s**\n",
    "- Otherwise, speeds remain in **px/s**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ce2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No animal height specified. Speed will be in pixels/second.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def init_speed_df(species_name: str):\n",
    "    if animal_height_m:\n",
    "        cols = [\"Video\", \"Image Width (px)\", \"t1 (s)\", \"x1 (px)\", \"y1 (px)\", \"label1\", \"t2 (s)\", \"x2 (px)\", \"y2 (px)\", \"label2\", \"speed (m/s)\"]\n",
    "        print(f\"Using height ~ {animal_height_m} m for conversion.\")\n",
    "        return pd.DataFrame(columns=cols), animal_height_m, True\n",
    "    else:\n",
    "        cols = [\"Video\", \"Image Width (px)\", \"t1 (s)\", \"x1 (px)\", \"y1 (px)\", \"label1\", \"t2 (s)\", \"x2 (px)\", \"y2 (px)\", \"label2\", \"speed (px/s)\"]\n",
    "        print(\"No animal height specified. Speed will be in pixels/second.\")\n",
    "        return pd.DataFrame(columns=cols), None, False\n",
    "\n",
    "df, animal_height_m, using_meters = init_speed_df(animal_height_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b140cc0",
   "metadata": {},
   "source": [
    "\n",
    "## ▶️ Run Tracking on Your Videos\n",
    "\n",
    "- Place videos in `SOURCE_FOLDER_PATH` (e.g., `.mp4, .avi, .mov`).\n",
    "- Annotated videos will be written into `OUTPUT_FOLDER`.\n",
    "- A running **speed table** is built and saved as `speed.csv` at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705de025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 04230105.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 1/1 [00:33<00:00, 33.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, uuid, cv2\n",
    "import logging\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.CRITICAL)\n",
    "\n",
    "if not os.path.exists(SOURCE_FOLDER_PATH):\n",
    "    raise FileNotFoundError(f\"Source video folder not found at {SOURCE_FOLDER_PATH}. Please create it and add videos.\")\n",
    "\n",
    "tracks = 0\n",
    "video_files = [f for f in os.listdir(SOURCE_FOLDER_PATH) if f.lower().endswith((\".mp4\", \".avi\", \".mov\"))]\n",
    "\n",
    "if not video_files:\n",
    "    print(\"No video files found. Add videos to the source folder and re-run this cell.\")\n",
    "else:\n",
    "    iterator = video_files\n",
    "    if tqdm is not None:\n",
    "        iterator = tqdm(video_files, desc=\"Processing videos\")\n",
    "\n",
    "    for video_name in iterator:\n",
    "        SOURCE_VIDEO_PATH = os.path.join(SOURCE_FOLDER_PATH, video_name)\n",
    "        TARGET_VIDEO_PATH = os.path.join(OUTPUT_FOLDER, f\"{os.path.splitext(video_name)[0]}_tracked.mp4\")\n",
    "        temp_basename = f\"{os.path.splitext(video_name)[0]}_{uuid.uuid4().hex}.tmp.mp4\"\n",
    "        TEMP_VIDEO_PATH = os.path.join(OUTPUT_FOLDER, temp_basename)\n",
    "        print(f\"\\nProcessing: {video_name}\")\n",
    "\n",
    "        try:\n",
    "            image_width_px, track_summaries = pw_utils.speed_in_video(\n",
    "                source_path=SOURCE_VIDEO_PATH,\n",
    "                target_path=TEMP_VIDEO_PATH,\n",
    "                callback=callback,\n",
    "                target_fps=10,\n",
    "                codec=\"mp4v\",\n",
    "                longest=assume_single_individual,\n",
    "                min_points=6,\n",
    "                min_duration_s=0.5,\n",
    "                min_displacement_px=20,\n",
    "                suppress_subtracks=True,\n",
    "                subtrack_radius_px=50,\n",
    "            )\n",
    "\n",
    "            os.replace(TEMP_VIDEO_PATH, TARGET_VIDEO_PATH)\n",
    "\n",
    "            # Each 'track' has two points (t1,x1,y1) and (t2,x2,y2) and a speed in px/s\n",
    "            for i, key in enumerate(track_summaries):\n",
    "                t1, x1, y1 = track_summaries[key]['points'][0]\n",
    "                t2, x2, y2 = track_summaries[key]['points'][1]\n",
    "                speed_px_s = track_summaries[key]['speed']\n",
    "                label1, label2 = track_summaries[key]['labels']\n",
    "\n",
    "                if using_meters and animal_height_m:\n",
    "                    # Convert px/s to m/s using width-scale (height_m / image_width_px)\n",
    "                    speed_val = (speed_px_s * animal_height_m) / image_width_px\n",
    "                else:\n",
    "                    speed_val = speed_px_s\n",
    "\n",
    "                df.loc[tracks] = [video_name, image_width_px, t1, x1, y1, label1, t2, x2, y2, label2, speed_val]\n",
    "                tracks += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {video_name}: {e}\")\n",
    "            if os.path.exists(TEMP_VIDEO_PATH):\n",
    "                    os.remove(TEMP_VIDEO_PATH)\n",
    "            continue\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f2ed6",
   "metadata": {},
   "source": [
    "\n",
    "## 💾 Save Results\n",
    "This writes a `speed.csv` into your output folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1729bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./speed_tracking_output/speed.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Image Width (px)</th>\n",
       "      <th>t1 (s)</th>\n",
       "      <th>x1 (px)</th>\n",
       "      <th>y1 (px)</th>\n",
       "      <th>...</th>\n",
       "      <th>t2 (s)</th>\n",
       "      <th>x2 (px)</th>\n",
       "      <th>y2 (px)</th>\n",
       "      <th>label2</th>\n",
       "      <th>speed (px/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04230105.MOV</td>\n",
       "      <td>3840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2597.503906</td>\n",
       "      <td>1628.817383</td>\n",
       "      <td>...</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2925.608887</td>\n",
       "      <td>1893.732788</td>\n",
       "      <td>Ortalis</td>\n",
       "      <td>40.548325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04230105.MOV</td>\n",
       "      <td>3840</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3378.365234</td>\n",
       "      <td>1644.980957</td>\n",
       "      <td>...</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3509.995361</td>\n",
       "      <td>1638.550293</td>\n",
       "      <td>Pecari</td>\n",
       "      <td>12.920305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04230105.MOV</td>\n",
       "      <td>3840</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3058.765869</td>\n",
       "      <td>1188.814087</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3142.447266</td>\n",
       "      <td>1243.586426</td>\n",
       "      <td>Ortalis</td>\n",
       "      <td>21.279346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Video  Image Width (px)  t1 (s)      x1 (px)      y1 (px)  ...  \\\n",
       "0  04230105.MOV              3840     0.0  2597.503906  1628.817383  ...   \n",
       "1  04230105.MOV              3840     0.2  3378.365234  1644.980957  ...   \n",
       "2  04230105.MOV              3840     0.5  3058.765869  1188.814087  ...   \n",
       "\n",
       "  t2 (s)      x2 (px)      y2 (px)   label2 speed (px/s)  \n",
       "0   10.4  2925.608887  1893.732788  Ortalis    40.548325  \n",
       "1   10.4  3509.995361  1638.550293   Pecari    12.920305  \n",
       "2    5.2  3142.447266  1243.586426  Ortalis    21.279346  \n",
       "\n",
       "[3 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "csv_path = os.path.join(OUTPUT_FOLDER, \"speed.csv\")\n",
    "if len(df) > 0:\n",
    "    df.to_csv(csv_path, index=False, float_format=\"%.3f\")\n",
    "    print(f\"Saved: {csv_path}\")\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"Speed table is empty—nothing to save yet.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
